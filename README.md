üè• An√°lise da Percep√ß√£o P√∫blica e Efic√°cia dos Investimentos na Sa√∫de de Belo Horizonte

Trabalho final da disciplina de Minera√ß√£o em Redes Sociais
Universidade Federal de Vi√ßosa (UFV) | Autor: Cleidimar Lacerda dos Passos
Contato: cleidimar.passos@ufv.br

üìä Sobre o Projeto

Este projeto explora a correla√ß√£o entre a satisfa√ß√£o do cidad√£o (avalia√ß√µes do Google Maps das UPAs de BH) e o volume dos investimentos p√∫blicos em sa√∫de. Utilizamos t√©cnicas de Web Scraping e PLN para analisar mais de 6.000 reviews e dados oficiais da PBH (2020‚Äì2025). O trabalho visa diagnosticar a efic√°cia do gasto p√∫blico.

‚ú® Principais Funcionalidades (Scripts Chave)

scraper_engine.py: Coleta autom√°tica de reviews, notas e datas das UPAs (Scraping).

preparar_dados_reais.py: Processa e filtra os grandes arquivos de despesas da PBH (ETL Financeiro).

analise_nlp.py: Processamento de texto, N-grams e Modelagem de T√≥picos (LDA).

analise_correlacao.py: Gera√ß√£o de gr√°ficos de correla√ß√£o temporal (Nota vs. Execu√ß√£o Or√ßament√°ria).

üõ†Ô∏è Tecnologias Utilizadas

Python 3.x

Selenium (coleta de dados)

Pandas (manipula√ß√£o e limpeza)

Matplotlib & Seaborn (visualiza√ß√£o)

Scikit-learn & NLTK (NLP e Modelagem)

üöÄ Como Reproduzir os Resultados (Passo a Passo)

Etapa 0: Configura√ß√£o Inicial

Clone o reposit√≥rio:

git clone [https://github.com/cleidimar-passos/tpfinal-analise-mineracao-midias.git](https://github.com/cleidimar-passos/tpfinal-analise-mineracao-midias.git)
cd tpfinal-analise-mineracao-midias




Instale as depend√™ncias:

pip install -r requirements.txt




<sub>Aten√ß√£o: O Selenium requer um Chrome/Edge Driver compat√≠vel.</sub>

Etapa 1: Obten√ß√£o e Prepara√ß√£o de Dados

A. Dados Financeiros (Oficiais da PBH - Obrigat√≥rio):

Baixe manualmente no Portal de Dados Abertos da PBH os arquivos de "Despesas Or√ßament√°rias" (2020‚Äì2025).

Crie a pasta dados_oficiais na raiz do projeto e coloque todos os arquivos CSV baixados dentro dela.

Execute o script de preparo financeiro:

python preparar_dados_reais.py




Resultado: Isso gera os arquivos dados_investimentos_geral.csv e dados_investimentos_hob.csv na raiz, necess√°rios para a correla√ß√£o.

B. Dados de Reviews (Coleta e Limpeza):

Execute o script de coleta de reviews do Google Maps:

python scraper_engine.py




Execute o script de limpeza e tratamento de datas (NLP B√°sico). Este passo √© crucial:

python processamento.py




Resultado: Isso gera o arquivo dados_limpos_upas.csv, unindo reviews e datas, que ser√° a base de todas as an√°lises subsequentes.

Etapa 2: An√°lises Finais e Gr√°ficos (Dependem da Etapa 1)

An√°lise de Texto (NLP):
(Requer dados_limpos_upas.csv)

python analise_nlp.py




Resultado: Imagens de Bi/Tri-grams e Modelagem de T√≥picos (LDA) salvas em resultados_nlp/.

Gera√ß√£o de Gr√°ficos Visuais (Rankings, Tempo):
(Requer dados_limpos_upas.csv)

python analise_visual.py




Resultado: Todos os gr√°ficos de ranking, volume e evolu√ß√£o temporal salvos em resultados_visuais/.

Correla√ß√£o Financeira:
(Requer dados_limpos_upas.csv E os arquivos dados_investimentos_*.csv)

Para rodar a an√°lise Geral, abra analise_correlacao.py e defina MODO_ANALISE = "GERAL".
Para rodar a an√°lise HOB, defina MODO_ANALISE = "HOB".

python analise_correlacao.py




Resultado: Gr√°ficos correlacao_geral.png e correlacao_hob.png gerados.

‚ö†Ô∏è Aviso Importante sobre Limita√ß√µes

Os datasets brutos originais da PBH (Despesas Or√ßament√°rias) N√ÉO est√£o inclu√≠dos no reposit√≥rio devido √† limita√ß√£o de 100MB por arquivo do GitHub.

O projeto √© totalmente reprodut√≠vel se os dados oficiais forem baixados conforme a Etapa 1.

Os arquivos de dados finais e intermedi√°rios (CSV leves) est√£o inclu√≠dos no reposit√≥rio.

üìÑ Artigo Cient√≠fico

O artigo gerado a partir destas an√°lises (artigo_final.tex) est√° dispon√≠vel na raiz do projeto.

üë®‚Äçüíª Autor

Cleidimar Lacerda dos Passos

Universidade Federal de Vi√ßosa (UFV)

cleidimar.passos@ufv.br

<sub>Projeto acad√™mico ‚Ä¢ Dados p√∫blicos ‚Ä¢ Uso exclusivamente educacional</sub>